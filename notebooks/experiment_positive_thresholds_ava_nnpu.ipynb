{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be79701e-a0aa-44c9-b936-af68fda94b46",
   "metadata": {},
   "source": [
    "# Experiments by changing the threshold of reliable positives (AVA dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633c6df3-c086-4f80-b8d1-c7cc4133018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab54073d-73f2-475f-95a2-3e2751729c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import os\n",
    "\n",
    "from pu.feature_extractors.extractors import ViTExtractor, AutoencoderExtractor\n",
    "from pu.data.loaders import CSVLoader, SingleCSVLoader, SingleCSVWithTestLoader, FullCSVLoader\n",
    "from pu.data.pu_builder import build_pu_data\n",
    "\n",
    "from pu.algorithms.pu_algorithms import IterativeClassifierAlgorithm, ProbTagging\n",
    "from pu.algorithms.negative_detectors import NaiveDetector, KNNDetector\n",
    "from pu.algorithms.stop_criterion import StopOnMetricDrop, NonStop\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29439db-a6ca-4d7e-bbc1-ad0b2fc5a88a",
   "metadata": {},
   "source": [
    "## AVA dataset for positive and unlabeled examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb83f474-fe0e-4e37-b5df-e78ed58b2908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_experiment(extractor, quantile):\n",
    "    ava_loader = FullCSVLoader(\n",
    "        '/srv/PU-dataset/unlabeled.csv',\n",
    "        'id',\n",
    "        '/srv/PU-dataset/dataset_unlabeled'\n",
    "    )\n",
    "    \n",
    "    ava_df = ava_loader.load_data()\n",
    "    features = extractor.extract_features(ava_df['id'])\n",
    "    ava_df = pd.concat([ava_df.drop(columns=['id']), features.drop(columns=['id'])], axis=1)\n",
    "\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = build_pu_data(\n",
    "        ava_df,\n",
    "        frac=1.0,\n",
    "        move_to_unlabeled_frac=0.5,\n",
    "        val_split=0.2,\n",
    "        val_split_positive='same',\n",
    "        reliable_positive_fn=lambda row, df: row['VotesMean'] > quantile,\n",
    "        positive_fn=lambda row, df: row['VotesMean'] >= 5.0,\n",
    "        test_frac=0.2,\n",
    "        random_state=1234\n",
    "    )\n",
    "\n",
    "    iterative_cls = IterativeClassifierAlgorithm(\n",
    "        negative_detector=KNNDetector(frac=0.1, k=20),\n",
    "        stop_criterion=NonStop('aul'),\n",
    "        classifier_class=LogisticRegression,\n",
    "        max_iterations=20,\n",
    "        verbose=True,\n",
    "        classifier_kwargs={'max_iter':10000, 'solver':'saga', 'n_jobs':-1, 'random_state':1234}\n",
    "    )\n",
    "    \n",
    "    iterative_cls.fit(X_train, y_train, X_val, y_val)\n",
    "    print(f'Evolution of f1 score: {iterative_cls.validation_results}')\n",
    "\n",
    "    bal_acc = balanced_accuracy_score(y_test, iterative_cls.predict(X_test))\n",
    "    acc = accuracy_score(y_test, iterative_cls.predict(X_test))\n",
    "    f1 = f1_score(y_test, iterative_cls.predict(X_test))\n",
    "\n",
    "    return bal_acc, acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6940ba0d-4f80-4516-9494-625765fc5ce3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount: 204278\n",
      "Validation amount: 40855\n",
      "Val_positive amount: 20434\n",
      "Val_unlabeled amount: 20421\n",
      "Train amount: 163423\n",
      "Known_positive amount: 40869\n",
      "Unlabeled_amount: 122554\n",
      "Size of positive paths: 102172\n",
      "Size of unlabeled paths: 102106\n",
      "Iteration #0\n",
      "Number of negatives: 12255\n",
      "Number of positives: 40869\n"
     ]
    }
   ],
   "source": [
    "extractors = ['clip-ViT-B-32', 'clip-ViT-B-16', 'clip-ViT-L-14']\n",
    "\n",
    "# Quantiles [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.99]\n",
    "quantile_quantities = [\n",
    "    5.386517,\n",
    "    5.475771,\n",
    "    5.566116,\n",
    "    5.660284,\n",
    "    5.758871,\n",
    "    5.865385,\n",
    "    5.987416,\n",
    "    6.129032,\n",
    "    6.307692,\n",
    "    6.574194,\n",
    "    7.069421\n",
    "]\n",
    "\n",
    "extractor_col, quantile_col, bal_acc_col, acc_col, f1_col = [], [], [], [], []\n",
    "\n",
    "for quantile in quantile_quantities:\n",
    "    for extractor in extractors:\n",
    "        try:\n",
    "            vit_extractor = ViTExtractor('quantile_experiments', extractor_name=extractor)\n",
    "            bal_acc, acc, f1 = quantile_experiment(vit_extractor, quantile)\n",
    "            extractor_col.append(extractor)\n",
    "            quantile_col.append(quantile)\n",
    "            bal_acc_col.append(bal_acc)\n",
    "            acc_col.append(acc)\n",
    "            f1_col.append(f1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Fail at {quantile}, {extractor}')\n",
    "            print(traceback.format_exc())\n",
    "\n",
    "df = pd.DataFrame.from_dict({\n",
    "    'extractor': extractor_col,\n",
    "    'quantile': quantile_col,\n",
    "    'balanced_accuracy': bal_acc_col,\n",
    "    'accuracy': acc_col,\n",
    "    'f1': f1_col\n",
    "})\n",
    "\n",
    "df.to_csv('quantile_threshold_vit_results_ava.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b063046-4882-47df-b1f8-dd2864556994",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 16:51:07.450545: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 16:51:07.463374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 16:51:07.463458: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 16:51:07.464436: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 16:51:07.464497: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 16:51:07.464537: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 16:51:07.938273: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 16:51:07.938359: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 16:51:07.938410: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-21 16:51:07.938456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9673 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount: 204278\n",
      "Validation amount: 40855\n",
      "Val_positive amount: 20434\n",
      "Val_unlabeled amount: 20421\n",
      "Train amount: 163423\n",
      "Known_positive amount: 40869\n",
      "Unlabeled_amount: 122554\n",
      "Size of positive paths: 102172\n",
      "Size of unlabeled paths: 102106\n",
      "Iteration #0\n",
      "Number of negatives: 12255\n",
      "Number of positives: 40869\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(filename)):\n\u001b[1;32m     25\u001b[0m     extractor \u001b[38;5;241m=\u001b[39m AutoencoderExtractor(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantile_experiments\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m3\u001b[39m), filters\u001b[38;5;241m=\u001b[39mfilters)\n\u001b[0;32m---> 26\u001b[0m     bal_acc, acc, f1 \u001b[38;5;241m=\u001b[39m \u001b[43mquantile_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextractor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     extractor_col\u001b[38;5;241m.\u001b[39mappend(filters)\n\u001b[1;32m     28\u001b[0m     quantile_col\u001b[38;5;241m.\u001b[39mappend(quantile)\n",
      "Cell \u001b[0;32mIn[3], line 42\u001b[0m, in \u001b[0;36mquantile_experiment\u001b[0;34m(extractor, quantile)\u001b[0m\n\u001b[1;32m     21\u001b[0m X_train, X_val, X_test, y_train, y_val, y_test \u001b[38;5;241m=\u001b[39m build_pu_data(\n\u001b[1;32m     22\u001b[0m     ava_df,\n\u001b[1;32m     23\u001b[0m     frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1234\u001b[39m\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m iterative_cls \u001b[38;5;241m=\u001b[39m IterativeClassifierAlgorithm(\n\u001b[1;32m     34\u001b[0m     negative_detector\u001b[38;5;241m=\u001b[39mKNNDetector(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m),\n\u001b[1;32m     35\u001b[0m     stop_criterion\u001b[38;5;241m=\u001b[39mNonStop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maul\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     classifier_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_iter\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m10000\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1234\u001b[39m}\n\u001b[1;32m     40\u001b[0m )\n\u001b[0;32m---> 42\u001b[0m \u001b[43miterative_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvolution of f1 score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miterative_cls\u001b[38;5;241m.\u001b[39mvalidation_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m bal_acc \u001b[38;5;241m=\u001b[39m balanced_accuracy_score(y_test, iterative_cls\u001b[38;5;241m.\u001b[39mpredict(X_test))\n",
      "File \u001b[0;32m~/src/aqa_pu/notebooks/../pu/algorithms/pu_algorithms.py:231\u001b[0m, in \u001b[0;36mTwoStepAlgorithm.fit\u001b[0;34m(self, X, y, X_val, y_val)\u001b[0m\n\u001b[1;32m    227\u001b[0m X_unlabeled \u001b[38;5;241m=\u001b[39m X[y \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    229\u001b[0m negatives, unlabeled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnegative_detector\u001b[38;5;241m.\u001b[39mdetect_negatives(X_positive, X_unlabeled)\n\u001b[0;32m--> 231\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_positive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegatives\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlabeled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/src/aqa_pu/notebooks/../pu/algorithms/pu_algorithms.py:338\u001b[0m, in \u001b[0;36mIterativeClassifierAlgorithm._fit\u001b[0;34m(self, positive, negative, unlabeled, X_val, y_val)\u001b[0m\n\u001b[1;32m    336\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X_train[shuffle_idxs]\n\u001b[1;32m    337\u001b[0m y_train \u001b[38;5;241m=\u001b[39m y_train[shuffle_idxs]\n\u001b[0;32m--> 338\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_verbose(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished training classifier\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    341\u001b[0m should_stop, val_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_criterion\u001b[38;5;241m.\u001b[39mcheck_stop(classifier, X_val, y_val)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1303\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1301\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1303\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1328\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "extractor_filters = [[8,16,16,32], [8,16,32,64,64], [8,16,32,64,64,128]]\n",
    "\n",
    "# Quantiles [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.99]\n",
    "quantile_quantities = [\n",
    "    5.386517,\n",
    "    5.475771,\n",
    "    5.566116,\n",
    "    5.660284,\n",
    "    5.758871,\n",
    "    5.865385,\n",
    "    5.987416,\n",
    "    6.129032,\n",
    "    6.307692,\n",
    "    6.574194,\n",
    "    7.069421\n",
    "]\n",
    "\n",
    "extractor_col, quantile_col, bal_acc_col, acc_col, f1_col = [], [], [], [], []\n",
    "\n",
    "for quantile in quantile_quantities:\n",
    "    for filters in extractor_filters:\n",
    "        try:\n",
    "            filename = f'quantile_threshold_autoencoder_results_{quantile}_{\"_\".join(str(i) for i in filters)}.csv'\n",
    "            if (not os.path.exists(filename)):\n",
    "                extractor = AutoencoderExtractor('quantile_experiments', input_shape=(256, 256, 3), filters=filters)\n",
    "                bal_acc, acc, f1 = quantile_experiment(extractor, quantile)\n",
    "                extractor_col.append(filters)\n",
    "                quantile_col.append(quantile)\n",
    "                bal_acc_col.append(bal_acc)\n",
    "                acc_col.append(acc)\n",
    "                f1_col.append(f1)\n",
    "    \n",
    "                df = pd.DataFrame.from_dict({\n",
    "                    'extractor': extractor_col,\n",
    "                    'quantile': quantile_col,\n",
    "                    'balanced_accuracy': bal_acc_col,\n",
    "                    'accuracy': acc_col,\n",
    "                    'f1': f1_col\n",
    "                })\n",
    "                \n",
    "                df.to_csv(filename)\n",
    "                extractor_col, quantile_col, bal_acc_col, acc_col, f1_col = [], [], [], [], []\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Fail at {quantile}, {extractor}')\n",
    "            print(traceback.format_exc())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
